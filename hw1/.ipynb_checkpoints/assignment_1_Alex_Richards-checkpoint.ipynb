{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Import all the necessary modules, packages, and libraries to complete this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.print_figure_kwargs={'bbox_inches':None}\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from math import sqrt\n",
    "from sklearn import linear_model, model_selection, preprocessing\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 1 (10pts) Linear regression with one variable from scratch \n",
    "Using Jupyter notebook, load the data (ex1data1.csv). Visualize data using scatter plot. The first column is Population of City in 10,000s, and the second column is profit of food truck in 10,000. In order to predict the profit, fit the data using gradient descent method (without matrix). You need to calculate cost function and update weight using gradient descent method. Try several different learning rate. Please print Root Mean Squared Error (RMSE) after optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Read in first dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('ex1data1.csv', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Visualize the first dataset as a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Plot data as a scatter plot\n",
    "formatting = {'fontsize': 15, 'weight': 'bold'}\n",
    "plt.title('Ex1data1', formatting)\n",
    "plt.xlabel('City Populations (10,000s)', formatting)\n",
    "plt.ylabel('Food Truck Profits (10,000s)', formatting)\n",
    "plt.xlim(min(data[0]) - 1, max(data[0]) + 1)\n",
    "plt.ylim(min(data[1]) - 1, max(data[1]) + 1)\n",
    "plt.grid(True)\n",
    "plt.scatter(data[0], data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Initialize variables and define functions used for learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Initialize learning rates, sample count, data samples, and data labels\n",
    "learning_rates, m, X, Y = [0.01, 1e-3, 1e-4], len(data), data[0], data[1]\n",
    "\n",
    "# Linear model\n",
    "model = lambda x: W0 + W1*x\n",
    "\n",
    "# Cost function\n",
    "J = lambda hyp: 1/m * sum([(y_hat - y)**2 for y_hat, y in zip(hyp, Y)])\n",
    "\n",
    "# Derivative of cost function w.r.t. W0\n",
    "dJ_dW0 = lambda hyp: 2/m * sum([y_hat - y for y_hat, y in zip(hyp, Y)])\n",
    "\n",
    "# Derivative of cost function w.r.t. W1\n",
    "dJ_dW1 = lambda hyp: 2/m * sum([(y_hat - y) * x for y_hat, y, x in zip(hyp, Y, X)])\n",
    "\n",
    "# Function for updating model parameters\n",
    "def update_weights(hypothesis, alpha, W0, W1):\n",
    "    W0 -= alpha*dJ_dW0(hypothesis)\n",
    "    W1 -= alpha*dJ_dW1(hypothesis)\n",
    "    return W0, W1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train a two parameter linear model on the first dataset using hand-written gradient descent method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The best model has:\n",
    "    RMSE = 2.992542935594168\n",
    "    learning rate = 0.01\n",
    "    W0 = -3.8090237940980507\n",
    "    W1 = 1.1843179540419724\n",
    "\"\"\"\n",
    "\n",
    "# Initialize weights and generate first hypothesis\n",
    "W0_init, W1_init = 0, 0\n",
    "W0, W1 = 0, 0\n",
    "Y_hat = pd.Series(list(map(model, X)))\n",
    "\n",
    "print('Initial RMSE: {:{align}{width}}'.format(\n",
    "    sqrt(J(Y_hat)), \n",
    "    align='>', \n",
    "    width=50-len(str(sqrt(J(Y_hat))))))\n",
    "\n",
    "# Train the model using different learning rates\n",
    "results = []\n",
    "for alpha in learning_rates:\n",
    "    \n",
    "    # Reinitialize weights and regenerate hypothesis\n",
    "    W0, W1 = W0_init, W1_init\n",
    "    Y_hat = pd.Series(list(map(model, X)))\n",
    "    \n",
    "    # Actually train the model\n",
    "    new_cost, old_cost, start, count = -1, 0, time(), 0\n",
    "    print('Performing gradient descent with a learning rate of {}'.format(alpha))\n",
    "\n",
    "    while new_cost < old_cost and abs(old_cost - new_cost) > 1e-5:\n",
    "        old_cost = J(Y_hat)\n",
    "        W0, W1 = update_weights(Y_hat, alpha, W0, W1)\n",
    "        Y_hat = pd.Series(list(map(model, X)))\n",
    "        new_cost = J(Y_hat)\n",
    "        if time() - start > 3:\n",
    "            start = time()\n",
    "            print('\\tCost: {}'.format(float(new_cost)))\n",
    "        count += 1\n",
    "        \n",
    "    print('Final RMSE w/ alpha={}: {:{align}{width}} achieved in {count} iterations\\n'.format(\n",
    "        alpha, \n",
    "        sqrt(J(Y_hat)), \n",
    "        align='>', \n",
    "        width=8-len(str(alpha))+len(str(sqrt(J(Y_hat)))),\n",
    "        count=count))\n",
    "    \n",
    "    # Append tuple of variables pertaining to this training run to a list of results \n",
    "    results.append((sqrt(J(Y_hat)), alpha, W0, W1))\n",
    "    \n",
    "print('\\nThe best model has:\\n\\tRMSE = {}\\n\\tlearning rate = {}\\n\\tW0 = {}\\n\\tW1 = {}'.format(*min(results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Visualize first dataset again with the model that has been fit to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Plot data as a scatter plot with the linear model fit to this data\n",
    "plt.title('Ex1data1 with Model Fit', formatting)\n",
    "plt.xlabel('City Populations (10,000s)', formatting)\n",
    "plt.ylabel('Food Truck Profits (10,000s)', formatting)\n",
    "plt.xlim(min(data[0]) - 1, max(data[0]) + 1)\n",
    "plt.ylim(min(data[1]) - 1, max(data[1]) + 1)\n",
    "plt.grid(True)\n",
    "plt.scatter(data[0], data[1])\n",
    "\n",
    "W0, W1 = min(results)[-2:]\n",
    "model = lambda x: W0 + W1*x\n",
    "Y_hat = pd.Series(list(map(model, X)))\n",
    "plt.plot(data[0], Y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 2 (30pts) Linear regression with multiple variables from scratch\n",
    "Using Jupyter notebook, load the data (ex1data2.csv). Visualize data. The first column is the size of the house (in square feet), the second column is the number of bedrooms, and the third column is the price of the house. In order to predict the housing price, fit the data using gradient descent method (without matrix). You need to calculate cost function and update weight using gradient descent method. Try several different learning rate. Please print the Root Mean Squared Error (RMSE) after optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Read in second dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('ex1data2.csv', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Visualize the second dataset as a 3D scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Plot data as a scatter plot\n",
    "formatting = {'fontsize': 15, 'weight': 'bold'}\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.set_title('Ex1data2', formatting)\n",
    "ax.set_xlabel('House Size (square feet)', formatting)\n",
    "ax.set_ylabel('Bedrooms', formatting)\n",
    "ax.set_zlabel('House Price', formatting)\n",
    "ax.set_xlim(min(data[0]) - 1, max(data[0]) + 1)\n",
    "ax.set_ylim(min(data[1]) - 1, max(data[1]) + 1)\n",
    "ax.set_zlim(min(data[2]) - 1, max(data[2]) + 1)\n",
    "ax.grid(True)\n",
    "ax.scatter(data[0], data[1], data[2])\n",
    "ax.view_init(10, 250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Initialize variables and define functions used for learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Initialize learning rates, sample count, data samples, and data labels\n",
    "learning_rates, m, X, Y, Z = [0.01, 1e-3, 1e-4] , len(data), data[0], data[1], data[2]\n",
    "\n",
    "# Min-max scale input\n",
    "X = preprocessing.minmax_scale(X)\n",
    "Y = preprocessing.minmax_scale(Y)\n",
    "\n",
    "# Linear model\n",
    "model = lambda x, y: W0 + W1*x + W2*y\n",
    "\n",
    "# Cost function\n",
    "J = lambda hyp: 1/m * sum([(z_hat - z)**2 for z_hat, z in zip(hyp, Z)])\n",
    "\n",
    "# Derivative of cost function w.r.t. W0\n",
    "dJ_dW0 = lambda hyp: 2/m * sum([z_hat - z for z_hat, z in zip(hyp, Z)])\n",
    "\n",
    "# Derivative of cost function w.r.t. W1\n",
    "dJ_dW1 = lambda hyp: 2/m * sum([(z_hat - z) * x for z_hat, z, x in zip(hyp, Z, X)])\n",
    "\n",
    "# Derivative of cost function w.r.t. W2\n",
    "dJ_dW2 = lambda hyp: 2/m * sum([(z_hat - z) * y for z_hat, z, y in zip(hyp, Z, Y)])\n",
    "\n",
    "# Function for updating model parameters\n",
    "def update_weights(hypothesis, alpha, W0, W1, W2):\n",
    "    W0 -= alpha*dJ_dW0(hypothesis)\n",
    "    W1 -= alpha*dJ_dW1(hypothesis)\n",
    "    W2 -= alpha*dJ_dW2(hypothesis)\n",
    "    return W0, W1, W2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train a three parameter linear model on the second dataset using hand-written gradient descent method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The best model has:\n",
    "    RMSE = 63926.214926312074\n",
    "    learning rate = 0.01\n",
    "    W0 = 199467.02647556202\n",
    "    W1 = 504777.15803839586\n",
    "    W2 = -34950.79328724869\n",
    "\"\"\"\n",
    "\n",
    "# Initialize weights and generate first hypothesis\n",
    "W0_init, W1_init, W2_init = 0, 0, 0\n",
    "W0, W1, W2 = W0_init, W1_init, W2_init\n",
    "\n",
    "Z_hat = pd.Series(list(map(model, X, Y)))\n",
    "\n",
    "print('Initial RMSE: {:{align}{width}}'.format(\n",
    "    sqrt(J(Z_hat)), \n",
    "    align='>', \n",
    "    width=56-len(str(sqrt(J(Z_hat))))))\n",
    "\n",
    "# Train the model using different learning rates\n",
    "results = []\n",
    "for alpha in learning_rates:\n",
    "    \n",
    "    # Reinitialize weights and regenerate hypothesis\n",
    "    W0, W1, W2 = W0_init, W1_init, W2_init\n",
    "    Z_hat = pd.Series(list(map(model, X, Y)))\n",
    "    \n",
    "    # Actually train the model\n",
    "    new_cost, old_cost, start, count = J(Z_hat), float('inf'), time(), 0\n",
    "    print('Performing gradient descent with a learning rate of {}'.format(alpha))\n",
    "    \n",
    "    while new_cost < old_cost and abs(old_cost - new_cost) > 1e-5:\n",
    "        old_cost = J(Z_hat)\n",
    "        W0, W1, W2 = update_weights(Z_hat, alpha, W0, W1, W2)\n",
    "        Z_hat = pd.Series(list(map(model, X, Y)))\n",
    "        new_cost = J(Z_hat)\n",
    "        if time() - start > 3:\n",
    "            start = time()\n",
    "            print('\\tCost: {}'.format(float(new_cost)))\n",
    "        count += 1\n",
    "        \n",
    "    print('\\n\\tFinal RMSE: {:{align}{width}} achieved in {count} iterations\\n'.format( \n",
    "        sqrt(J(Z_hat)), \n",
    "        align='>', \n",
    "        width=8-len(str(alpha))+len(str(sqrt(J(Z_hat)))),\n",
    "        count=count))\n",
    "    \n",
    "    # Append tuple of variables pertaining to this training run to a list of results \n",
    "    results.append((sqrt(J(Z_hat)), alpha, W0, W1, W2))\n",
    "    \n",
    "print('\\nThe best model has:\\n\\tRMSE = {}\\n\\tlearning rate = {}\\n\\tW0 = {}\\n\\tW1 = {}\\n\\tW2 = {}'.format(*min(results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Visualize second dataset again with the model that has been fit to it (see note below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### NOTE: I had to execute this cell a couple of times in order to get the figure to display properly\n",
    "\n",
    "# Enable embedded interactive figures\n",
    "%matplotlib notebook\n",
    "\n",
    "# Plot data as a scatter plot with the linear model fit to this data\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.set_title('Ex1data2 with Model Fit', formatting)\n",
    "ax.set_xlabel('House Size (square feet)', formatting)\n",
    "ax.set_ylabel('Bedrooms', formatting)\n",
    "ax.set_zlabel('House Price', formatting)\n",
    "ax.set_xlim(min(data[0]) - 1, max(data[0]) + 1)\n",
    "ax.set_ylim(min(data[1]) - 1, max(data[1]) + 1)\n",
    "ax.set_zlim(min(data[2]) - 1, max(data[2]) + 1)\n",
    "ax.grid(True)\n",
    "ax.scatter(data[0], data[1], data[2])\n",
    "\n",
    "W0, W1, W2 = min(results)[-3:]\n",
    "model = lambda x, y: W0 + W1*x + W2*y\n",
    "Z_hat = pd.Series(list(map(model, X, Y)))\n",
    "X_grid, Y_grid = np.meshgrid(data[0], data[1])\n",
    "ax.plot_surface(X_grid, Y_grid, Z_hat.values.reshape(-1, len(Z_hat)), \n",
    "                cmap=plt.cm.cool, rstride=1, cstride=1, linewidth=0)\n",
    "ax.view_init(10, 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 2-1 Linear regression with multiple variables using matrix\n",
    "Fit the data (ex1data2.csv) using matrix calculation. You need to calculate cost function and update weight. Please print the Root Mean Squared Error (RMSE) after optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train a three parameter linear model on the second dataset using matrix form of gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The best model has:\n",
    "    RMSE = 438256.0494456521\n",
    "    learning rate = 0.01\n",
    "    W = 199467.04656177355\n",
    "        504777.2005826939\n",
    "        -34950.854535530394\n",
    "\"\"\"\n",
    "\n",
    "# Read in second dataset as a min-max scaled matrix\n",
    "X = np.stack([\n",
    "        pd.Series([1 for _ in range(len(data))]),\n",
    "        preprocessing.minmax_scale(data[0]),\n",
    "        preprocessing.minmax_scale(data[1])],\n",
    "        axis=1)\n",
    "y = np.asmatrix(data.iloc[:, -1]).reshape(len(data), -1)\n",
    "\n",
    "# Initialize weights and learning rate\n",
    "W_init = np.asmatrix(np.array([0., 0., 0.]).reshape(3, -1))\n",
    "W = np.copy(W_init)\n",
    "\n",
    "# Define cost, cost derivative, and weight updating functions\n",
    "J = lambda: np.dot((np.dot(X, W) - y).T, np.dot(X, W) - y)\n",
    "dJ_dW = lambda: (1/len(data)) * (np.dot(np.dot(X.T, X), W) - np.dot(X.T, y))\n",
    "\n",
    "def update_weights(W, alpha):\n",
    "    W -= alpha*dJ_dW()\n",
    "    return W\n",
    "\n",
    "print('Initial RMSE: {}'.format(sqrt(float(J()))))\n",
    "\n",
    "# Train the model using different learning rates\n",
    "results = []\n",
    "for alpha in learning_rates:\n",
    "    \n",
    "    # Reinitialize weights and regenerate hypothesis\n",
    "    W = np.copy(W_init)\n",
    "    print('Performing gradient descent with a learning rate of {}'.format(alpha))\n",
    "\n",
    "    # Actually train the model\n",
    "    new_cost, old_cost, start, count = J(), float('inf'), time(), 0\n",
    "    while new_cost < old_cost and abs(old_cost - new_cost) > 1e-5:\n",
    "        old_cost = float(new_cost)\n",
    "        W = update_weights(W, alpha)\n",
    "        new_cost = float(J())\n",
    "        if time() - start > 3:\n",
    "            print('\\tCost: {}'.format(new_cost))\n",
    "            start = time()\n",
    "        count += 1\n",
    "            \n",
    "    print('\\n\\tFinal RMSE: {:{align}{width}} achieved after {count} iterations\\n'.format( \n",
    "        sqrt(J()), \n",
    "        align='>', \n",
    "        width=8-len(str(alpha))+len(str(sqrt(J()))),\n",
    "        count=count))\n",
    "    \n",
    "    # Append tuple of variables pertaining to this training run to a list of results \n",
    "    results.append((sqrt(J()), alpha, W))\n",
    "\n",
    "print('\\nThe best model has:\\n\\tRMSE = {}\\n\\tlearning rate = {}\\n\\tW = {}'.format(min(results)[0], min(results)[1], '\\n\\t    '.join([str(float(r)) for r in min(results)[2]])))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 2-2 Linear regression with multiple variables using Normal equation\n",
    "Fit the data (ex1data2.csv) using Normal equation. You need to calculate cost function and update weight. Please print the best Root Mean Squared Error (RMSE) after optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Solve for the three parameters of a linear model of the second dataset using the Normal equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "RMSE = 438256.04944473004\n",
    "W = 199467.31126290312\n",
    "    504777.7612421374\n",
    "    -34951.66168074836\n",
    "\"\"\"\n",
    "\n",
    "# Read in second dataset\n",
    "X = np.asmatrix(np.stack([\n",
    "        pd.Series([1 for _ in range(len(data))]),\n",
    "        preprocessing.minmax_scale(data[0]),\n",
    "        preprocessing.minmax_scale(data[1])],\n",
    "        axis=1))\n",
    "y = np.asmatrix(data.iloc[:, -1]).reshape(len(data), -1)\n",
    "\n",
    "# Compute parameter vector using the normal equation\n",
    "A = np.dot(np.dot(np.dot(X.T, X).I, X.T), y)\n",
    "E = y - np.dot(X, A)\n",
    "rmse = float(np.sqrt(np.dot(E.T, E)))\n",
    "print('RMSE = {}\\nW = {}'.format(rmse, '\\n    '.join([str(float(r)) for r in A])))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 3 (60pts) Linear regression with multiple variables\n",
    "Using Jupyter notebook, load the data (ex1data3.csv). This is California housing dataset. The original database is available from http://lib.stat.cmu.edu. The data contains 20,640 observations on 9 variables. This dataset contains the average house value as target variable and the following input variables (features): average income, housing average age, average rooms, average bedrooms, population, average occupation, latitude, and longitude.\n",
    "\n",
    "# 3-1 Linear regression with multiple variables using matrix\n",
    "Fit the data (ex1data3.csv) using matrix calculation. You need to calculate cost function and update weight. Please print the Root Mean Squared Error (RMSE) after optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Read in third dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('ex1data3.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train a nine parameter linear model on the third dataset using matrix form of gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The best model has:\n",
    "    RMSE = 104.03021929026632\n",
    "    learning rate = 1\n",
    "    W = 3.7438201818696153\n",
    "        6.298436669789026\n",
    "        0.4817518525935022\n",
    "        -14.525994891093307\n",
    "        21.05149821863349\n",
    "        -0.13927671151288115\n",
    "        -4.692790632065271\n",
    "        -3.978486565206663\n",
    "        -4.375322933050189\n",
    "\"\"\"\n",
    "\n",
    "# Scale input and add column of 1s for bias\n",
    "data_matrix = data.as_matrix(columns=data.columns[:-1])\n",
    "X = np.asmatrix(np.stack([\n",
    "        pd.Series([1 for _ in range(len(data))])] +\n",
    "        [preprocessing.minmax_scale(c) for c in data_matrix.T],\n",
    "        axis=1))\n",
    "y = np.asmatrix(data.iloc[:, -1]).reshape(len(data), -1)\n",
    "\n",
    "# Initialize weights and learning rate; define cost, cost derivative, and weight updating functions \n",
    "W_init = np.asmatrix(np.array([0., 0., 0., 0., 0., 0., 0., 0., 0.,]).reshape(9, -1))\n",
    "W = np.copy(W_init)\n",
    "\n",
    "print('Initial RMSE: {}'.format(sqrt(float(J()))))\n",
    "\n",
    "# Train the model using different learning rates\n",
    "results = []\n",
    "for alpha in [1, 0.1, 0.001]:\n",
    "\n",
    "    # Reinitialize weights and regenerate hypothesis\n",
    "    W = np.copy(W_init)\n",
    "    print('Performing gradient descent with a learning rate of {}'.format(alpha))\n",
    "    \n",
    "    # Actually train the model\n",
    "    new_cost, old_cost, start, count = J(), float('inf'), time(), 0\n",
    "    while new_cost < old_cost and abs(old_cost - new_cost) > 1e-5:\n",
    "        old_cost = float(new_cost)\n",
    "        W = update_weights(W, alpha)\n",
    "        new_cost = float(J())\n",
    "        if time() - start > 3:\n",
    "            print('\\tCost: {}'.format(new_cost))\n",
    "            start = time()\n",
    "        count += 1\n",
    "\n",
    "    print('\\n\\tFinal RMSE: {:{align}{width}} achieved in {count} iterations\\n'.format( \n",
    "        sqrt(J()), \n",
    "        align='>', \n",
    "        width=8-len(str(alpha))+len(str(sqrt(J()))),\n",
    "        count=count))\n",
    "    \n",
    "    # Append tuple of variables pertaining to this training run to a list of results \n",
    "    results.append((sqrt(J()), alpha, W))\n",
    "    \n",
    "print('\\nThe best model has:\\n\\tRMSE = {}\\n\\tlearning rate = {}\\n\\tW = {}'.format(min(results)[0], min(results)[1], '\\n\\t    '.join([str(float(r)) for r in min(results)[2]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 3-2 Linear regression with multiple variables using Normal equation\n",
    "Fit the data (ex1data3.csv) using Normal equation. You need to calculate cost function and update weight. Please print the best Root Mean Squared Error (RMSE) after optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Solve for the nine parameters of a linear model of the third dataset using the Normal equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "RMSE = 104.0287708033252\n",
    "W = -36.94192020501217\n",
    "    0.43669329313947347\n",
    "    0.009435778033647648\n",
    "    -0.10732204139597243\n",
    "    0.6450656935355646\n",
    "    -3.9763894200357455e-06\n",
    "    -0.0037865426550375055\n",
    "    -0.4213143775044826\n",
    "    -0.4345137546496847\n",
    "\"\"\"\n",
    "\n",
    "# Read in third dataset\n",
    "X = np.asmatrix(pd.concat([\n",
    "        pd.Series([1 for _ in range(len(data))]),\n",
    "        data.iloc[:,:-1]],\n",
    "        axis=1))\n",
    "y = np.asmatrix(data.iloc[:, -1]).reshape(len(data), -1)\n",
    "\n",
    "# Compute parameter vector using the normal equation\n",
    "A = np.dot(np.dot(np.dot(X.T, X).I, X.T), y)\n",
    "E = y - np.dot(X, A)\n",
    "rmse = float(np.sqrt(np.dot(E.T, E)))\n",
    "print('RMSE = {}\\nW = {}'.format(rmse, '\\n    '.join([str(float(r)) for r in A])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 3-3 Linear regression with multiple variables using scikit-learn linear regression model\n",
    "Fit the data (ex1data3.csv) using linear regression from scikit-learn library. You need to calculate cost function and update weight. Please print the best Root Mean Squared Error (RMSE) after optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fit scikit-learn's LinearRegression model to the third dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "RMSE: 0.1510883358410674\n",
    "Intercept: 0.7209011985953243\n",
    "Parameters:\n",
    "    1.33003796426\n",
    "    0.10042274589\n",
    "    -3.54812550664\n",
    "    5.41918337218\n",
    "    -0.000565705359492\n",
    "    -0.845372904001\n",
    "    -0.81319750181\n",
    "    -0.898635226232\n",
    "\"\"\"\n",
    "\n",
    "# Split third dataset into training/testing\n",
    "X, y = data.iloc[:,:-1], data.iloc[:, -1]\n",
    "X = preprocessing.minmax_scale(X)\n",
    "y = preprocessing.minmax_scale(y)\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Fit linear regression model\n",
    "model = linear_model.LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# RMSE and model coefficients\n",
    "print(\"RMSE: {}\\nIntercept: {}\\nParameters:\\n\\t{}\".format(\n",
    "        sqrt(np.mean((model.predict(X_test) - y_test)**2)),\n",
    "        model.intercept_,\n",
    "        '\\n\\t'.join([str(c) for c in model.coef_])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 3-4 Linear regression with multiple variables using TensorFlow\n",
    "Fit the data (ex1data3.csv) using linear regression using TensorFlow. Please do not use Normal equation TensorFlow. You need to calculate cost function and update weight. Please print the best Root Mean Squared Error (RMSE) after optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fit a TensorFlow linear model to the third dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Epochs: 100\n",
    "RMSE: 0.7517409920692444\n",
    "W: 5.27824259\n",
    "   0.42344368\n",
    "   0.55639106\n",
    "   2.4778235 \n",
    "   -0.13599038\n",
    "   -1.12633598\n",
    "   -3.46945238\n",
    "   -3.73285103\n",
    "b: 3.31386828\n",
    "   3.31386828  \n",
    "   3.31386828  \n",
    "   3.31386828  \n",
    "   3.31386828  \n",
    "   3.31386828\n",
    "   3.31386828  \n",
    "   3.31386828\n",
    "\"\"\"\n",
    "\n",
    "some_stuff = data.as_matrix(columns=data.columns[:-1])\n",
    "data_matrix = np.asmatrix(np.stack(\n",
    "        [preprocessing.minmax_scale(c) for c in some_stuff.T],\n",
    "        axis=1))\n",
    "labels = np.asmatrix(data.iloc[:, -1]).reshape(len(data), 1)\n",
    "\n",
    "W = tf.Variable(tf.zeros([data_matrix.shape[1], 1]), name='weights')\n",
    "b = tf.Variable(tf.zeros([1, data_matrix.shape[1]]), name='bias')\n",
    "\n",
    "X = tf.placeholder(tf.float32, name='X')\n",
    "Y = tf.placeholder(tf.float32, name='Y')\n",
    "\n",
    "Y_predicted = b + tf.matmul(X, W)\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(Y_predicted - Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(loss)\n",
    "epochs = 100\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        for x, y in zip(data_matrix, labels):\n",
    "            sess.run(optimizer, feed_dict={X: x, Y: y})\n",
    "            \n",
    "        c = sess.run(loss, feed_dict={X: data_matrix, Y: labels})\n",
    "        print('Epoch: {:03d}    cost= {:.9f}'.format(i+1, c))\n",
    "            \n",
    "    w_val, b_val = sess.run([W, b])\n",
    "    rmse = sess.run(tf.sqrt(loss), feed_dict={X: data_matrix, Y: labels})\n",
    "    \n",
    "print(\"RMSE: {}\\nW: {}\\nb: {}\".format(rmse, w_val, b_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
